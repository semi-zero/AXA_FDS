{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Library Import**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import roc_auc_score, recall_score, precision_score, confusion_matrix\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from pytorch_tabnet.tab_model import TabNetClassifier, TabNetRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/site-packages/IPython/core/interactiveshell.py:3063: DtypeWarning: Columns (623) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    }
   ],
   "source": [
    "data=pd.read_csv('FDS_MART(20210804).csv',encoding='cp949')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **새로운 feature 생성 -p28d_acc_addr_count**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     2021-02-28 00:00:00\n",
      "     20210131\n",
      "     20210227\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime, timedelta\n",
    "\n",
    "data['FRST_RCV_DT_dtime'] = 0\n",
    "\n",
    "def int_to_dt(x):\n",
    "    x = str(x)\n",
    "    return datetime(year=int(x[0:4]), month=int(x[4:6]), day=int(x[6:8]))\n",
    "\n",
    "data['FRST_RCV_DT_dtime'] = data['FRST_RCV_DT'].apply(lambda x : int_to_dt(x) )\n",
    "data['FRST_RCV_DT_dtime']\n",
    "\n",
    "d0228 = data['FRST_RCV_DT_dtime'].iloc[-1]\n",
    "print('    ',d0228)\n",
    "d28 = timedelta(days = 28)\n",
    "p28days = (pd.date_range(d0228 - d28, periods=28)).strftime('%Y%m%d')\n",
    "print('    ',p28days[0])\n",
    "print('    ',p28days[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO: Pandarallel will run on 8 workers.\n",
      "INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0            0\n",
       "1            0\n",
       "2            0\n",
       "3            0\n",
       "4            0\n",
       "          ... \n",
       "136544    2596\n",
       "136545    2596\n",
       "136546    2596\n",
       "136547    2596\n",
       "136548    2596\n",
       "Name: p28d_acc_addr_count, Length: 136549, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pandarallel import pandarallel\n",
    "\n",
    "pandarallel.initialize(nb_workers=8)\n",
    "\n",
    "d28 = timedelta(days = 28)\n",
    "# d14 = timedelta(days = 14)\n",
    "\n",
    "def p28d_acc_addr_count(x):\n",
    "    \n",
    "    p28days = (pd.date_range(x - d28, periods=28)).strftime('%Y%m%d')\n",
    "    return len(\n",
    "        data[(data['FRST_RCV_DT_dtime']>=p28days[0])&(data['FRST_RCV_DT_dtime']<=p28days[-1])]\n",
    "    )\n",
    "\n",
    "data['p28d_acc_addr_count'] = 0\n",
    "\n",
    "data['p28d_acc_addr_count'] = data['FRST_RCV_DT_dtime'].parallel_apply(lambda x :p28d_acc_addr_count(x) )\n",
    "data['p28d_acc_addr_count']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUST_RANK is not in train_cols\n",
      "RULE_APLY_CNT is not in train_cols\n",
      "SIU_CLAS_CD_TOTAL is not in train_cols\n",
      "INSR_MODEL is not in train_cols\n",
      "CONT_MODEL is not in train_cols\n",
      "INJ_MODEL is not in train_cols\n",
      "INJ_POS_MODEL is not in train_cols\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0         0.0\n",
       "1         0.0\n",
       "2         0.0\n",
       "3         0.0\n",
       "4         0.0\n",
       "         ... \n",
       "136544    0.0\n",
       "136545    0.0\n",
       "136546    0.0\n",
       "136547    0.0\n",
       "136548    0.0\n",
       "Name: cube6_CATH_AMT, Length: 136549, dtype: float64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_data=data\n",
    "\n",
    "raw_data['cube6_CATH_AMT'] =0\n",
    "\n",
    "def cube6_transform(x):\n",
    "    return x**(1/6)\n",
    "\n",
    "raw_data['cube6_CATH_AMT'] = raw_data['CATH_AMT'].apply(lambda x : cube6_transform(x) )\n",
    "\n",
    "# target = data['CATH_AMT']**(1/6)\n",
    "\n",
    "not_na_col_ls = []\n",
    "\n",
    "for col in raw_data.columns:\n",
    "    if raw_data[col].isna().any() == False:\n",
    "        not_na_col_ls.append(col)\n",
    "        \n",
    "target_feat = [\n",
    "    'FDS_REQ',\n",
    "    'CEMP_REQ',\n",
    "    'SIU_REQ',\n",
    "    'SIU_CEMP_REQ',\n",
    "    'CUST_RANK',\n",
    "    'RULE_APLY_CNT',\n",
    "    'RUL_CNT',\n",
    "    'SIU_CLAS_CD1',\n",
    "    'SIU_CLAS_CD_TOTAL',\n",
    "    'BOGUS_ACDNT_CD',\n",
    "    'PREDICT_MODEL',\n",
    "    'HYBRID_MODEL',\n",
    "    'HYBRID_RED',\n",
    "    'HYBRID_ORANGE',\n",
    "    'HYBRID_YELLOW',\n",
    "    'FDS_CATH',\n",
    "    'CEMP_CATH',\n",
    "    'SIU_CATH',\n",
    "    'SIU_CEMP_CATH',\n",
    "    'CATH_AMT',\n",
    "    'INSR_MODEL',\n",
    "    'CONT_MODEL',\n",
    "    'INJ_MODEL',\n",
    "    'INJ_POS_MODEL',\n",
    "    'ALT_GUBUN']\n",
    "\n",
    "for t_feat in target_feat:\n",
    "    try:\n",
    "        not_na_col_ls.remove(t_feat)\n",
    "    except:\n",
    "        print(t_feat, 'is not in train_cols')\n",
    "        pass\n",
    "    \n",
    "not_na_col_ls.remove('ACDNT_NO')\n",
    "not_na_col_ls.remove('POLICY_NO')\n",
    "not_na_col_ls.remove('FRST_RCV_DT')\n",
    "not_na_col_ls.remove('cube6_CATH_AMT')\n",
    "\n",
    "cat_cols = not_na_col_ls\n",
    "\n",
    "raw_data['cube6_CATH_AMT']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **train, test split**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_cols = ['ACDNT_TOTAL_TEXT_1', 'ACDNT_CLAS_CD2', 'DRUNK_YN', 'MAKER_G', 'DRIVER_LICNS_STAT', 'ACCO_BI_A_MAX_DIST', 'ACCO_BI_A_AVG_DIST', 'APPD_A_MAX_DIST', 'APPD_OCD_AVG_DIST', 'APPD_A_AVG_DIST', 'CAR_TYPE_NM', 'ACC_ADDR1', 'APPD_OCD_MAX_DIST', 'INS_TYPE_CO_VAL', 'APVC_A_AVG_DIST', 'DRIVER_LICNS_AREA', 'APVC_A_MAX_DIST', 'DISPATCH_TOWING', 'DRIVER_VOCTN_TST_GAP_G', 'POLICE_RPRT_CD', 'LIC_2M', 'CURE_YN', 'OAI_FALT_RATE_G', 'DRIVER_LICNS_YEAR', 'LIC_1M', 'FPC', 'ACC_AREA_RANK', 'LICNS_TYPE_CD', 'ADK_HOUSE_TYPE_DTL', 'APVC_OTH_MAX_DIST', 'DRVER_AGE', 'ACDNT_POL_GAP', 'ACDNT_INSPCT_TEXT', 'APVC_OTH_AVG_DIST', 'LIC_1L', 'DRIVER_RANGE_SPCL_105', 'N_APROF_01', 'N_BPROF_05', 'INSRD_RLATN', 'MNG_AREA_CD', 'N_BPROF_09', 'N_PROF_15', 'N_PROF_14', 'N_APROF_31', 'HO_AP_DIST', 'N_BPROF_10', 'N_APROF_30', 'N_APROF_12', 'N_CPROF_05', 'N_PROF_13', 'FDS_CATH','cube6_CATH_AMT']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_data['ACC_AREA_RANK'].fillna('A', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = raw_data[cat_cols].iloc[:118888]\n",
    "test = raw_data[cat_cols].iloc[118888:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "train=train[train['FDS_CATH']=='Y']\n",
    "train.reset_index(drop=True, inplace=True)\n",
    "train.drop('FDS_CATH', axis=1, inplace=True)\n",
    "test.drop('FDS_CATH', axis=1, inplace=True)\n",
    "\n",
    "target='cube6_CATH_AMT'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **기존 모델**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ACDNT_TOTAL_TEXT_1 4\n",
      "ACDNT_CLAS_CD2 4\n",
      "DRUNK_YN 2\n",
      "MAKER_G 12\n",
      "DRIVER_LICNS_STAT 3\n",
      "CAR_TYPE_NM 7\n",
      "ACC_ADDR1 17\n",
      "INS_TYPE_CO_VAL 6\n",
      "DRIVER_LICNS_AREA 18\n",
      "DISPATCH_TOWING 4\n",
      "DRIVER_VOCTN_TST_GAP_G 7\n",
      "POLICE_RPRT_CD 3\n",
      "LIC_2M 3\n",
      "CURE_YN 3\n",
      "OAI_FALT_RATE_G 6\n",
      "DRIVER_LICNS_YEAR 55\n",
      "LIC_1M 3\n",
      "FPC 3\n",
      "ACC_AREA_RANK 4\n",
      "LICNS_TYPE_CD 4\n",
      "ADK_HOUSE_TYPE_DTL 4\n",
      "DRVER_AGE 74\n",
      "ACDNT_INSPCT_TEXT 2\n",
      "LIC_1L 3\n",
      "DRIVER_RANGE_SPCL_105 7\n",
      "INSRD_RLATN 5\n"
     ]
    }
   ],
   "source": [
    "nunique = train.nunique()\n",
    "types = train.dtypes\n",
    "\n",
    "categorical_columns=[]\n",
    "categorical_dims ={}\n",
    "\n",
    "for col in train.columns:\n",
    "    if types[col] == 'object' or nunique[col] <200:\n",
    "        print(col, train[col].nunique())\n",
    "        l_enc= LabelEncoder()\n",
    "        train[col]= train[col].fillna(\"VV_likely\")\n",
    "        train[col]= l_enc.fit_transform(train[col].values)\n",
    "        #test[col]= l_enc.transform(test[col].values)\n",
    "        categorical_columns.append(col)\n",
    "        categorical_dims[col] = len(l_enc.classes_)\n",
    "    else:\n",
    "        train.fillna(train.loc[train.index, col].mean(), inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "features =[col for col in train.columns if col not in [target]]\n",
    "cat_idxs = [i for i, f in enumerate(features) if f in categorical_columns]\n",
    "cat_dims = [categorical_dims[f] for i, f in enumerate(features) if f in categorical_columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x=train[features].values\n",
    "train_y=train[target].values\n",
    "train_y=train_y.reshape(-1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ACDNT_TOTAL_TEXT_1 4\n",
      "ACDNT_CLAS_CD2 4\n",
      "DRUNK_YN 2\n",
      "MAKER_G 14\n",
      "DRIVER_LICNS_STAT 3\n",
      "CAR_TYPE_NM 7\n",
      "ACC_ADDR1 18\n",
      "INS_TYPE_CO_VAL 6\n",
      "DRIVER_LICNS_AREA 18\n",
      "DISPATCH_TOWING 4\n",
      "DRIVER_VOCTN_TST_GAP_G 7\n",
      "POLICE_RPRT_CD 3\n",
      "LIC_2M 3\n",
      "CURE_YN 3\n",
      "OAI_FALT_RATE_G 7\n",
      "DRIVER_LICNS_YEAR 64\n",
      "LIC_1M 3\n",
      "FPC 3\n",
      "ACC_AREA_RANK 4\n",
      "LICNS_TYPE_CD 4\n",
      "ADK_HOUSE_TYPE_DTL 4\n",
      "DRVER_AGE 75\n",
      "ACDNT_INSPCT_TEXT 2\n",
      "LIC_1L 3\n",
      "DRIVER_RANGE_SPCL_105 9\n",
      "INSRD_RLATN 5\n"
     ]
    }
   ],
   "source": [
    "#nunique = train.nunique()\n",
    "#types = train.dtypes\n",
    "\n",
    "categorical_columns=[]\n",
    "categorical_dims ={}\n",
    "\n",
    "for col in test.columns:\n",
    "    if types[col] == 'object' or nunique[col] <200:\n",
    "        print(col, test[col].nunique())\n",
    "        l_enc= LabelEncoder()\n",
    "        test[col]= test[col].fillna(\"VV_likely\")\n",
    "        test[col]= l_enc.fit_transform(test[col].values)\n",
    "        categorical_columns.append(col)\n",
    "        categorical_dims[col] = len(l_enc.classes_)\n",
    "    else:\n",
    "        test.fillna(test.loc[:, col].mean(), inplace=True)\n",
    "        \n",
    "\n",
    "test_x=test[features].values\n",
    "test_y=test[target].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "import optuna\n",
    "from optuna import Trial, visualization\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "def Objective(trial):\n",
    "    mask_type = trial.suggest_categorical(\"mask_type\", [\"entmax\", \"sparsemax\"])\n",
    "    n_da = trial.suggest_int(\"n_da\", 56, 64, step=4)\n",
    "    n_steps = trial.suggest_int(\"n_steps\", 1, 3, step=1)\n",
    "    gamma = trial.suggest_float(\"gamma\",  1., 1.4, step=0.2)\n",
    "    n_shared = trial.suggest_int(\"n_shared\", 1, 3)\n",
    "    lambda_sparse = trial.suggest_float(\"lambda_sparse\", 1e-6, 1e-3, log=True)\n",
    "    tabnet_params=dict(n_d=n_da, n_a=n_da, n_steps=n_steps, gamma=gamma,\n",
    "                      lambda_sparse=lambda_sparse, optimizer_fn=torch.optim.Adam,\n",
    "                      optimizer_params=dict(lr=2e-2, weight_decay=1e-5),\n",
    "                      mask_type=mask_type, n_shared=n_shared,\n",
    "                      scheduler_params=dict(mode=\"min\", patience=trial.suggest_int(\"patienceScheduler\", low=3, high=10),\n",
    "                                           min_lr=1e-5, \n",
    "                                           factor=0.5),\n",
    "                      scheduler_fn=torch.optim.lr_scheduler.ReduceLROnPlateau,\n",
    "                      verbose=0\n",
    "                      )\n",
    "    \n",
    "    kf=KFold(n_splits=10, random_state=42, shuffle=True)\n",
    "    CV_score_array = []\n",
    "    for train_index, val_index in kf.split(train_x, train_y):\n",
    "        X_train, X_val = train_x[train_index], train_x[val_index]\n",
    "        y_train, y_val = train_y[train_index], train_y[val_index]\n",
    "        reg=TabNetRegressor(**tabnet_params)\n",
    "        reg.fit(X_train=X_train, y_train=y_train, \n",
    "               eval_set=[(X_train, y_train), (X_val, y_val)],\n",
    "               patience=trial.suggest_int(\"patience\", low=15, high=30), max_epochs=trial.suggest_int('epochs', 1, 100),\n",
    "               eval_metric=['mse'])\n",
    "        CV_score_array.append(reg.best_cost)\n",
    "    avg=np.mean(CV_score_array)\n",
    "    return avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.set_num_threads(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 38 with best_epoch = 18 and best_val_1_mse = 5.89588\n",
      "Best weights from best epoch are automatically used!\n",
      "\n",
      "Early stopping occurred at epoch 33 with best_epoch = 13 and best_val_1_mse = 7.67662\n",
      "Best weights from best epoch are automatically used!\n",
      "Stop training because you reached max_epochs = 86 with best_epoch = 73 and best_val_1_mse = 7.45359\n",
      "Best weights from best epoch are automatically used!\n",
      "\n",
      "Early stopping occurred at epoch 32 with best_epoch = 12 and best_val_1_mse = 8.37413\n",
      "Best weights from best epoch are automatically used!\n",
      "\n",
      "Early stopping occurred at epoch 57 with best_epoch = 37 and best_val_1_mse = 9.59735\n",
      "Best weights from best epoch are automatically used!\n",
      "\n",
      "Early stopping occurred at epoch 32 with best_epoch = 12 and best_val_1_mse = 10.74524\n",
      "Best weights from best epoch are automatically used!\n",
      "Stop training because you reached max_epochs = 86 with best_epoch = 73 and best_val_1_mse = 9.77754\n",
      "Best weights from best epoch are automatically used!\n",
      "\n",
      "Early stopping occurred at epoch 43 with best_epoch = 23 and best_val_1_mse = 7.45982\n",
      "Best weights from best epoch are automatically used!\n",
      "\n",
      "Early stopping occurred at epoch 66 with best_epoch = 46 and best_val_1_mse = 9.23534\n",
      "Best weights from best epoch are automatically used!\n",
      "\n",
      "Early stopping occurred at epoch 66 with best_epoch = 46 and best_val_1_mse = 8.33468\n",
      "Best weights from best epoch are automatically used!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2021-12-08 13:52:50,296] Finished trial#0 with value: 8.455019596690317 with parameters: {'mask_type': 'entmax', 'n_da': 56, 'n_steps': 1, 'gamma': 1.2, 'n_shared': 1, 'lambda_sparse': 0.00020250441157316552, 'patienceScheduler': 9, 'patience': 20, 'epochs': 86}. Best is trial#0 with value: 8.455019596690317.\n"
     ]
    }
   ],
   "source": [
    "study_nfs=optuna.create_study(direction='minimize', study_name='TabNet optimization')\n",
    "study_nfs.optimize(Objective, n_trials=100, timeout=180)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "TabNet_params = study_nfs.best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TabNet_params ={'mask_type': 'entmax', 'n_da': 64, 'n_steps': 1, 'gamma': 1.4, 'n_shared': 3, 'lambda_sparse': 2.3368609952485577e-06, 'patienceScheduler': 8, 'patience': 18, 'epochs': 35}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'mask_type': 'entmax', 'n_da': 56, 'n_steps': 1, 'gamma': 1.2, 'n_shared': 1, 'lambda_sparse': 0.00020250441157316552, 'patienceScheduler': 9, 'patience': 20, 'epochs': 86}\n"
     ]
    }
   ],
   "source": [
    "print(TabNet_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_params = dict(n_d=TabNet_params['n_da'], n_a=TabNet_params['n_da'], n_steps=TabNet_params['n_steps'], gamma=TabNet_params['gamma'],\n",
    "                     lambda_sparse=TabNet_params['lambda_sparse'], optimizer_fn=torch.optim.Adam,\n",
    "                     optimizer_params=dict(lr=2e-2, weight_decay=1e-5),\n",
    "                     mask_type=TabNet_params['mask_type'], n_shared=TabNet_params['n_shared'],\n",
    "                     scheduler_params=dict(mode=\"min\",\n",
    "                                           patience=TabNet_params['patienceScheduler'],\n",
    "                                           min_lr=1e-5,\n",
    "                                           factor=0.5,),\n",
    "                     scheduler_fn=torch.optim.lr_scheduler.ReduceLROnPlateau,\n",
    "                     verbose=10,\n",
    "                     )\n",
    "epochs = TabNet_params['epochs']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device used : cpu\n",
      "No early stopping will be performed, last training weights will be used.\n",
      "epoch 0  | loss: 96.41173|  0:00:00s\n",
      "epoch 10 | loss: 6.13846 |  0:00:06s\n",
      "epoch 20 | loss: 3.88524 |  0:00:12s\n",
      "epoch 30 | loss: 2.43968 |  0:00:18s\n",
      "epoch 40 | loss: 1.69755 |  0:00:24s\n",
      "epoch 50 | loss: 1.33387 |  0:00:29s\n",
      "epoch 60 | loss: 1.06426 |  0:00:35s\n",
      "epoch 70 | loss: 0.93891 |  0:00:41s\n",
      "epoch 80 | loss: 0.82511 |  0:00:46s\n"
     ]
    }
   ],
   "source": [
    "regressor = TabNetRegressor(**final_params)\n",
    "regressor.fit(X_train=train_x, y_train=train_y, \n",
    "              patience=TabNet_params['patience'], max_epochs=epochs, eval_metric=['mse'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH='/home/users/adk8400153/AXA_FDS/AUTO_FDS/optuna_tabnet_reg.pth'\n",
    "torch.save(regressor, PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test 정답 도출\n",
    "test_prediction=np.zeros((test.shape[0], 2))\n",
    "model=torch.load(PATH)\n",
    "test_prediction = model.predict(test_x)\n",
    "test_prediction=test_prediction**6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "#####################################\n",
    "reg_path = '/home/users/adk8400153/AXA_FDS/AUTO_FDS/optuna_tabnet_reg.pth' #경로 지정 필요\n",
    "reg_cols = ['ACDNT_TOTAL_TEXT_1', 'ACDNT_CLAS_CD2', 'DRUNK_YN', 'MAKER_G', 'DRIVER_LICNS_STAT', 'ACCO_BI_A_MAX_DIST', 'ACCO_BI_A_AVG_DIST', 'APPD_A_MAX_DIST', 'APPD_OCD_AVG_DIST', 'APPD_A_AVG_DIST', 'CAR_TYPE_NM', 'ACC_ADDR1', 'APPD_OCD_MAX_DIST', 'INS_TYPE_CO_VAL', 'APVC_A_AVG_DIST', 'DRIVER_LICNS_AREA', 'APVC_A_MAX_DIST', 'DISPATCH_TOWING', 'DRIVER_VOCTN_TST_GAP_G', 'POLICE_RPRT_CD', 'LIC_2M', 'CURE_YN', 'OAI_FALT_RATE_G', 'DRIVER_LICNS_YEAR', 'LIC_1M', 'FPC', 'ACC_AREA_RANK', 'LICNS_TYPE_CD', 'ADK_HOUSE_TYPE_DTL', 'APVC_OTH_MAX_DIST', 'DRVER_AGE', 'ACDNT_POL_GAP', 'ACDNT_INSPCT_TEXT', 'APVC_OTH_AVG_DIST', 'LIC_1L', 'DRIVER_RANGE_SPCL_105', 'N_APROF_01', 'N_BPROF_05', 'INSRD_RLATN', 'MNG_AREA_CD', 'N_BPROF_09', 'N_PROF_15', 'N_PROF_14', 'N_APROF_31', 'HO_AP_DIST', 'N_BPROF_10', 'N_APROF_30', 'N_APROF_12', 'N_CPROF_05', 'N_PROF_13']\n",
    "reg_model = torch.load(reg_path)\n",
    "\n",
    "reg_prediction = pd.DataFrame(model.predict(test_x)**6 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.145318e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5.796030e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.476628e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.007487e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9.278599e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17656</th>\n",
       "      <td>2.308355e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17657</th>\n",
       "      <td>2.548579e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17658</th>\n",
       "      <td>2.019416e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17659</th>\n",
       "      <td>8.655658e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17660</th>\n",
       "      <td>1.348020e+06</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>17661 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  0\n",
       "0      5.145318e+06\n",
       "1      5.796030e+05\n",
       "2      1.476628e+06\n",
       "3      1.007487e+06\n",
       "4      9.278599e+00\n",
       "...             ...\n",
       "17656  2.308355e+05\n",
       "17657  2.548579e+06\n",
       "17658  2.019416e+06\n",
       "17659  8.655658e+05\n",
       "17660  1.348020e+06\n",
       "\n",
       "[17661 rows x 1 columns]"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reg_prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **classifier 예측값 도출**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "#5. Fraud Detection by Deep Learning 파일 참조!\n",
    "cat_prediction=pd.read_csv('cat_tabnet_test_prediction.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>p0</th>\n",
       "      <th>p1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.932708</td>\n",
       "      <td>0.067292</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.985572</td>\n",
       "      <td>0.014428</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.995532</td>\n",
       "      <td>0.004469</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.990771</td>\n",
       "      <td>0.009229</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.986624</td>\n",
       "      <td>0.013376</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17656</th>\n",
       "      <td>0.993602</td>\n",
       "      <td>0.006398</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17657</th>\n",
       "      <td>0.987951</td>\n",
       "      <td>0.012049</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17658</th>\n",
       "      <td>0.945076</td>\n",
       "      <td>0.054924</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17659</th>\n",
       "      <td>0.984969</td>\n",
       "      <td>0.015031</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17660</th>\n",
       "      <td>0.980974</td>\n",
       "      <td>0.019026</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>17661 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             p0        p1\n",
       "0      0.932708  0.067292\n",
       "1      0.985572  0.014428\n",
       "2      0.995532  0.004469\n",
       "3      0.990771  0.009229\n",
       "4      0.986624  0.013376\n",
       "...         ...       ...\n",
       "17656  0.993602  0.006398\n",
       "17657  0.987951  0.012049\n",
       "17658  0.945076  0.054924\n",
       "17659  0.984969  0.015031\n",
       "17660  0.980974  0.019026\n",
       "\n",
       "[17661 rows x 2 columns]"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cat_prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **결과값 도출**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>group</th>\n",
       "      <th colspan=\"3\" halign=\"left\">CATH_AMT</th>\n",
       "      <th colspan=\"3\" halign=\"left\">Y</th>\n",
       "      <th colspan=\"3\" halign=\"left\">0</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>sum</th>\n",
       "      <th>mean</th>\n",
       "      <th>count</th>\n",
       "      <th>sum</th>\n",
       "      <th>mean</th>\n",
       "      <th>count</th>\n",
       "      <th>sum</th>\n",
       "      <th>mean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>G01</td>\n",
       "      <td>1766</td>\n",
       "      <td>355565479</td>\n",
       "      <td>201339.455832</td>\n",
       "      <td>1766</td>\n",
       "      <td>84</td>\n",
       "      <td>0.047565</td>\n",
       "      <td>1766</td>\n",
       "      <td>4.868186e+08</td>\n",
       "      <td>275661.704498</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>G02</td>\n",
       "      <td>1766</td>\n",
       "      <td>96679504</td>\n",
       "      <td>54744.906002</td>\n",
       "      <td>1766</td>\n",
       "      <td>41</td>\n",
       "      <td>0.023216</td>\n",
       "      <td>1766</td>\n",
       "      <td>9.804364e+07</td>\n",
       "      <td>55517.350290</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>G03</td>\n",
       "      <td>1766</td>\n",
       "      <td>62086031</td>\n",
       "      <td>35156.302945</td>\n",
       "      <td>1766</td>\n",
       "      <td>29</td>\n",
       "      <td>0.016421</td>\n",
       "      <td>1766</td>\n",
       "      <td>5.949306e+07</td>\n",
       "      <td>33688.031416</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>G04</td>\n",
       "      <td>1766</td>\n",
       "      <td>39226215</td>\n",
       "      <td>22211.899773</td>\n",
       "      <td>1766</td>\n",
       "      <td>16</td>\n",
       "      <td>0.009060</td>\n",
       "      <td>1766</td>\n",
       "      <td>4.022290e+07</td>\n",
       "      <td>22776.275384</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>G05</td>\n",
       "      <td>1766</td>\n",
       "      <td>37805705</td>\n",
       "      <td>21407.533975</td>\n",
       "      <td>1766</td>\n",
       "      <td>13</td>\n",
       "      <td>0.007361</td>\n",
       "      <td>1766</td>\n",
       "      <td>2.875668e+07</td>\n",
       "      <td>16283.511633</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>G06</td>\n",
       "      <td>1766</td>\n",
       "      <td>66901189</td>\n",
       "      <td>37882.892978</td>\n",
       "      <td>1766</td>\n",
       "      <td>15</td>\n",
       "      <td>0.008494</td>\n",
       "      <td>1766</td>\n",
       "      <td>2.063995e+07</td>\n",
       "      <td>11687.398499</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>G07</td>\n",
       "      <td>1766</td>\n",
       "      <td>31521077</td>\n",
       "      <td>17848.854473</td>\n",
       "      <td>1766</td>\n",
       "      <td>17</td>\n",
       "      <td>0.009626</td>\n",
       "      <td>1766</td>\n",
       "      <td>1.464078e+07</td>\n",
       "      <td>8290.363481</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>G08</td>\n",
       "      <td>1766</td>\n",
       "      <td>3849000</td>\n",
       "      <td>2179.501699</td>\n",
       "      <td>1766</td>\n",
       "      <td>5</td>\n",
       "      <td>0.002831</td>\n",
       "      <td>1766</td>\n",
       "      <td>1.011078e+07</td>\n",
       "      <td>5725.244564</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>G09</td>\n",
       "      <td>1766</td>\n",
       "      <td>32815613</td>\n",
       "      <td>18581.887316</td>\n",
       "      <td>1766</td>\n",
       "      <td>7</td>\n",
       "      <td>0.003964</td>\n",
       "      <td>1766</td>\n",
       "      <td>5.978285e+06</td>\n",
       "      <td>3385.212166</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>G10</td>\n",
       "      <td>1767</td>\n",
       "      <td>12492710</td>\n",
       "      <td>7070.011319</td>\n",
       "      <td>1767</td>\n",
       "      <td>2</td>\n",
       "      <td>0.001132</td>\n",
       "      <td>1767</td>\n",
       "      <td>2.277343e+06</td>\n",
       "      <td>1288.819122</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  group CATH_AMT                               Y                   0  \\\n",
       "           count        sum           mean count sum      mean count   \n",
       "0   G01     1766  355565479  201339.455832  1766  84  0.047565  1766   \n",
       "1   G02     1766   96679504   54744.906002  1766  41  0.023216  1766   \n",
       "2   G03     1766   62086031   35156.302945  1766  29  0.016421  1766   \n",
       "3   G04     1766   39226215   22211.899773  1766  16  0.009060  1766   \n",
       "4   G05     1766   37805705   21407.533975  1766  13  0.007361  1766   \n",
       "5   G06     1766   66901189   37882.892978  1766  15  0.008494  1766   \n",
       "6   G07     1766   31521077   17848.854473  1766  17  0.009626  1766   \n",
       "7   G08     1766    3849000    2179.501699  1766   5  0.002831  1766   \n",
       "8   G09     1766   32815613   18581.887316  1766   7  0.003964  1766   \n",
       "9   G10     1767   12492710    7070.011319  1767   2  0.001132  1767   \n",
       "\n",
       "                                \n",
       "            sum           mean  \n",
       "0  4.868186e+08  275661.704498  \n",
       "1  9.804364e+07   55517.350290  \n",
       "2  5.949306e+07   33688.031416  \n",
       "3  4.022290e+07   22776.275384  \n",
       "4  2.875668e+07   16283.511633  \n",
       "5  2.063995e+07   11687.398499  \n",
       "6  1.464078e+07    8290.363481  \n",
       "7  1.011078e+07    5725.244564  \n",
       "8  5.978285e+06    3385.212166  \n",
       "9  2.277343e+06    1288.819122  "
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "expected_cath = pd.DataFrame(cat_prediction['p1']*reg_prediction[0]) #classifier의 probability와 regressor의 amount 곱하기\n",
    "test_target = raw_data.iloc[118888:]['CATH_AMT']\n",
    "test_target2 = pd.get_dummies(raw_data.iloc[118888:]['FDS_CATH'])['Y']\n",
    "\n",
    "score = pd.concat([test_target.reset_index(drop=True),test_target2.reset_index(drop=True),pd.DataFrame(expected_cath).reset_index(drop=True)[0]],axis=1)\n",
    "\n",
    "######캡 씌우기#######\n",
    "threshold = 18488000\n",
    "\n",
    "\n",
    "score.loc[score['CATH_AMT']>threshold, 'CATH_AMT']=threshold\n",
    "score.sort_values(0, ascending=False, inplace=True)\n",
    "score=score.reset_index().drop('index', axis=1).copy()\n",
    "\n",
    "####################################################################################\n",
    "n_group=10\n",
    "group=['G01','G02','G03','G04','G05','G06','G07','G08','G09','G10']\n",
    "\n",
    "bins=round(len(score)/n_group) \n",
    "bins_1=len(score)-bins*(n_group-1) \n",
    "\n",
    "group_list=[]\n",
    "for i in range(n_group):\n",
    "    if i <n_group-1: \n",
    "        group_list.append(np.repeat(group[i], bins).tolist())\n",
    "    else: \n",
    "        group_list.append(np.repeat(group[i], bins_1).tolist())\n",
    "    \n",
    "import itertools\n",
    "\n",
    "group_list=list(itertools.chain(*group_list))\n",
    "score['group']=pd.Series(group_list)\n",
    "\n",
    "function_list=['count','sum','mean']\n",
    "table2=score.groupby(['group']).agg(function_list).reset_index()\n",
    "\n",
    "table2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
